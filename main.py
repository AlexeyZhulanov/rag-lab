import asyncio
import logging
import os
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import CommandStart

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è RAG
import ollama
import chromadb

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
load_dotenv()
TOKEN = os.getenv("BOT_TOKEN")
EMBED_MODEL = "nomic-embed-text"  # –ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–∏—Å–∫–∞
CHAT_MODEL = "gemma2:9b"  # –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(level=logging.INFO)

bot = Bot(token=TOKEN)
dp = Dispatcher()

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
collection = None


# --- –§–£–ù–ö–¶–ò–ò RAG (–õ–æ–≥–∏–∫–∞ –ø–æ–∏—Å–∫–∞) ---

def init_db():
    """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∏ —Å–æ–∑–¥–∞–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞"""
    global collection
    print("‚è≥ –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB –≤ –ø–∞–º—è—Ç–∏
    client = chromadb.Client()
    # –ï—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –±—ã–ª–∞, —É–¥–∞–ª—è–µ–º –µ—ë (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ)
    try:
        client.delete_collection("knowledge_base")
    except:
        pass

    collection = client.create_collection(name="knowledge_base")

    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
    try:
        with open("knowledge.txt", "r", encoding="utf-8") as f:
            text = f.read()
    except FileNotFoundError:
        print("‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª knowledge.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ (–ø–æ –ø—É—Å—Ç—ã–º —Å—Ç—Ä–æ–∫–∞–º)
    chunks = [chunk.strip() for chunk in text.split("\n\n") if chunk.strip()]

    # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É
    for i, chunk in enumerate(chunks):
        response = ollama.embeddings(model=EMBED_MODEL, prompt=chunk)
        collection.add(
            ids=[str(i)],
            embeddings=[response["embedding"]],
            documents=[chunk]
        )

    print(f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≥–æ—Ç–æ–≤–∞! –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")


def get_rag_response(user_question):
    """–ò—â–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç LLM"""

    # 1. –ò—â–µ–º –≤ –±–∞–∑–µ
    response = ollama.embeddings(model=EMBED_MODEL, prompt=user_question)
    results = collection.query(
        query_embeddings=[response["embedding"]],
        n_results=1  # –ë–µ—Ä–µ–º 1 —Å–∞–º—ã–π –ø–æ—Ö–æ–∂–∏–π –∫—É—Å–æ–∫
    )

    if not results['documents'] or not results['documents'][0]:
        found_text = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç."
    else:
        found_text = results['documents'][0][0]

    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
    prompt = f"""
    –¢—ã ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ.
    –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, –æ—Ç–≤–µ—Ç—å —Ñ—Ä–∞–∑–æ–π: "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –º–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
    –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏—á–µ–≥–æ –æ—Ç —Å–µ–±—è.

    –ö–æ–Ω—Ç–µ–∫—Å—Ç:
    {found_text}

    –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
    {user_question}
    """

    # 3. –°–ø—Ä–∞—à–∏–≤–∞–µ–º Gemma
    output = ollama.chat(model=CHAT_MODEL, messages=[
        {'role': 'user', 'content': prompt}
    ])

    return output['message']['content']


# --- –•–ï–ù–î–õ–ï–†–´ TELEGRAM ---

@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ç–æ—Å—Ç–µ—Ä–∞ Omega-3000.\n"
        "–Ø —Ä–∞–±–æ—Ç–∞—é –Ω–∞ –±–∞–∑–µ RAG (Gemma 2 + ChromaDB).\n"
        "–°–ø—Ä–æ—Å–∏ –º–µ–Ω—è –ø—Ä–æ –∫–æ–¥—ã –æ—à–∏–±–æ–∫ –∏–ª–∏ —Ä–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã."
    )


@dp.message(F.text)
async def handle_text(message: types.Message):
    user_text = message.text

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å "–ø–µ—á–∞—Ç–∞–µ—Ç..."
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")

    # –ó–∞–ø—É—Å–∫–∞–µ–º RAG –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ (—á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –±–æ—Ç–∞)
    # –í aiogram 3 –¥–ª—è —Ç—è–∂–µ–ª—ã—Ö –∑–∞–¥–∞—á –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å to_thread
    response_text = await asyncio.to_thread(get_rag_response, user_text)

    await message.answer(response_text)


# --- –ó–ê–ü–£–°–ö ---
async def main():
    # –°–Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∏–º –±–∞–∑—É
    init_db()

    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")